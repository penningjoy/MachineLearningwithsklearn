{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2 _FeatureEngineering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp5LDG6M+3WtjkSEwa4XYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penningjoy/MachineLearningwithsklearn/blob/main/Part_2__FeatureEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I52F0VDiaQ8U"
      },
      "source": [
        "### Feature Selection\n",
        "\n",
        "Feature Selection is a very important part of Feature Engineering process. You  don't want features that are not relevant and unrelated to your target and thus do not have to participate in the Machine Learning process. \n",
        "\n",
        "Reasons behind performing feature selection --\n",
        "\n",
        "*   Reduction in Training time because you have less garbage\n",
        "*   Reduced Dimension\n",
        "*   More General and easier model \n",
        "*   Better Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcGOMzDtgVAy"
      },
      "source": [
        "#### Removing features with low variance\n",
        "\n",
        "It involves removing features which has only one value and other instances share the same value on this feature. There is no variance in its instances. Therefore it will not contribute anything to the prediction. And thus it's best to remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQfB3qBuf-CA",
        "outputId": "5ad48b7f-ba30-4a4d-bc66-c75bd3ef3e83"
      },
      "source": [
        "import sklearn.feature_selection as fs\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]])\n",
        "\n",
        "'''\n",
        "VarianceThreshold function removes features with low variance based on a \n",
        "threshold. Threshold is the variance threshold.\n",
        "'''\n",
        "\n",
        "variance = fs.VarianceThreshold(threshold = 0.2)\n",
        "variance.fit(X)\n",
        "X_transformed = variance.transform(X)\n",
        "\n",
        "print(\" Original Data \")\n",
        "print(\" ------------- \")\n",
        "print(X)\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "print(\" Label Encoded Data \")\n",
        "print(\" -------------- \")\n",
        "print(X_transformed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original Data \n",
            " ------------- \n",
            "[[0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [0 1 1]]\n",
            " \n",
            " Label Encoded Data \n",
            " -------------- \n",
            "[[0 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQlIbssLjCqc"
      },
      "source": [
        "#### Select K-Best Features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHV08TqoKZX"
      },
      "source": [
        "import sklearn.datasets as datasets\n",
        "\n",
        "X, Y = datasets.make_classification(n_samples=300, n_features=10, n_informative=4)\n",
        "\n",
        "# Choosing the f_classif as the metric and K is 3\n",
        "kbest = fs.SelectKBest( fs.f_classif, 3)\n",
        "kbest.fit(X,Y)\n",
        "\n",
        "X_transformed = kbest.transform(X)\n",
        "\n",
        "print(\" Original Data \")\n",
        "print(\" ------------- \")\n",
        "print(X)\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "print(\" Label Encoded Data \")\n",
        "print(\" -------------- \")\n",
        "print(X_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg40Fi6btHOy"
      },
      "source": [
        " #### Feature Selection by other model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJe9sp-YRwPP",
        "outputId": "1dc961ed-0005-49ef-94ca-2e9ebc79e9df"
      },
      "source": [
        "import sklearn.feature_selection as fs\n",
        "import sklearn.datasets as datasets\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "X, Y = datasets.make_classification(n_samples=500, n_features=20, n_informative=6,random_state=21)\n",
        "\n",
        "gbclassifier = GradientBoostingClassifier(n_estimators=20)\n",
        "gbclassifier.fit(X,Y)\n",
        "\n",
        "print(\"Feature Selection using GBDT\")\n",
        "print(gbclassifier.feature_importances_)\n",
        "\n",
        "gbdtmodel = fs.SelectFromModel(gbclassifier, prefit= True)\n",
        "\n",
        "# The features with very low importance will be removed\n",
        "X_transformed = gbdtmodel.transform(X)  \n",
        "\n",
        "print(\" Original Data Shape \")\n",
        "print(\" ------------- \")\n",
        "print(X.shape)\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "print(\" Transformed Data Shape after Feature Selection \")\n",
        "print(\" -------------- \")\n",
        "print(X_transformed.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Selection using GBDT\n",
            "[0.         0.00493847 0.         0.00773537 0.         0.13557457\n",
            " 0.1600879  0.         0.         0.0490113  0.04407025 0.04873479\n",
            " 0.0078042  0.         0.005109   0.         0.53693415 0.\n",
            " 0.         0.        ]\n",
            " Original Data Shape \n",
            " ------------- \n",
            "(500, 20)\n",
            " \n",
            " Transformed Data \n",
            " -------------- \n",
            "(500, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSgp9V20wH_9"
      },
      "source": [
        "### Feature Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53mXhva8yy8m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFj949XyzSB"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "    \"I have an apple.\", \"The apple is red\", \"I like the apple\",\n",
        "    \"I like the orange\", \"Apple and orange are fruit\", \"The orange is yellow\"\n",
        "]\n",
        "\n",
        "counterVec = CountVectorizer()\n",
        "\n",
        "counterVec.fit(corpus)\n",
        "\n",
        "print(\"Get all the feature names of this corpus\")\n",
        "\n",
        "print(counterVec.get_feature_names())\n",
        "\n",
        "print(\"The number of feature is {}\".format(len(\n",
        "    counterVec.get_feature_names())))\n",
        "\n",
        "corpus_data = counterVec.transform(corpus)\n",
        "\n",
        "print(\"The transform data's shape is {}\".format(corpus_data.toarray().shape))\n",
        "\n",
        "print(corpus_data.toarray())"
      ]
    }
  ]
}